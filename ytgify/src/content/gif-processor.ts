// Content Script GIF Processor - Handles complete GIF creation in content script
import { logger } from '@/lib/logger';
import { createError } from '@/lib/errors';
import { encodeFrames, FrameData as EncoderFrameData, EncodingOptions } from '@/lib/encoders';
import { TextOverlay } from '@/types';
import { metricsCollector } from '@/monitoring/metrics-collector';
import { StorageAdapter } from '@/lib/storage/storage-adapter';
import { apiClient } from '@/lib/api/api-client';
import type { UploadGifParams, UploadedGif } from '@/types/auth';

/**
 * Compare two canvas frames to detect if they are similar/duplicate
 * @param canvas1 First canvas to compare
 * @param canvas2 Second canvas to compare
 * @param threshold Similarity threshold (0-1), default 0.98 means 98% similar pixels
 * @returns true if frames are considered duplicates
 */
function areCanvasFramesSimilar(
  canvas1: HTMLCanvasElement,
  canvas2: HTMLCanvasElement,
  threshold = 0.98
): boolean {
  if (canvas1.width !== canvas2.width || canvas1.height !== canvas2.height) {
    return false;
  }

  const ctx1 = canvas1.getContext('2d', { willReadFrequently: true });
  const ctx2 = canvas2.getContext('2d', { willReadFrequently: true });

  if (!ctx1 || !ctx2) {
    return false;
  }

  const imageData1 = ctx1.getImageData(0, 0, canvas1.width, canvas1.height);
  const imageData2 = ctx2.getImageData(0, 0, canvas2.width, canvas2.height);

  const data1 = imageData1.data;
  const data2 = imageData2.data;
  const totalPixels = data1.length / 4;
  const sampleSize = Math.min(1000, totalPixels);
  const step = Math.max(4, Math.floor(data1.length / sampleSize / 4) * 4);

  let matches = 0;
  let samples = 0;

  for (let i = 0; i < data1.length && samples < sampleSize; i += step) {
    // Compare RGB values (skip alpha channel)
    if (data1[i] === data2[i] && data1[i + 1] === data2[i + 1] && data1[i + 2] === data2[i + 2]) {
      matches++;
    }
    samples++;
  }

  if (samples === 0) {
    return false;
  }

  const similarity = matches / samples;
  return similarity > threshold;
}

interface GifProcessingOptions {
  startTime: number;
  endTime: number;
  frameRate?: number;
  width?: number;
  height?: number;
  quality?: 'low' | 'medium' | 'high';
  textOverlays?: TextOverlay[];
}

interface GifProcessingResult {
  blob: Blob;
  metadata: {
    fileSize: number;
    duration: number;
    frameCount: number;
    width: number;
    height: number;
    fps: number; // Phase 2: Added for backend upload
    id: string;
  };
}

export interface BufferingStatus {
  isBuffering: boolean;
  currentFrame: number;
  totalFrames: number;
  bufferedPercentage: number;
  estimatedTimeRemaining: number;
}

/** @internal */
export interface StageProgressInfo {
  stage: string;
  stageNumber: number;
  totalStages: number;
  stageName: string;
  message: string;
  progress: number;
  bufferingStatus?: BufferingStatus;
}

export class ContentScriptGifProcessor {
  private static instance: ContentScriptGifProcessor;
  private isProcessing = false;
  private isAborting = false;
  private abortRequestTime: number | null = null;
  private messageTimer: NodeJS.Timeout | null = null;
  private currentStage: string | null = null;
  private messageIndex = 0;
  private progressCallback: ((stageInfo: StageProgressInfo) => void) | undefined = undefined;

  // Reusable canvases to avoid creating new ones for every frame
  private mainCanvas: HTMLCanvasElement | null = null;
  private mainCtx: CanvasRenderingContext2D | null = null;
  private recoveryCanvas: HTMLCanvasElement | null = null;
  private recoveryCtx: CanvasRenderingContext2D | null = null;

  // Stage definitions
  private stages = {
    CAPTURING: {
      name: 'Capturing Frames',
      icon: 'üìπ',
      messages: [
        'Reading video data...',
        'Extracting frames...',
        'Processing frame timings...',
        'Capturing pixel data...',
        'Organizing frame sequence...',
      ],
    },
    ANALYZING: {
      name: 'Analyzing Colors',
      icon: 'üé®',
      messages: [
        'Scanning color distribution...',
        'Finding dominant colors...',
        'Building color histogram...',
        'Optimizing palette...',
        'Reducing to 256 colors...',
      ],
    },
    ENCODING: {
      name: 'Encoding GIF',
      icon: 'üîß',
      messages: [
        'Initializing encoder...',
        'Writing frame data...',
        'Applying compression...',
        'Optimizing frame deltas...',
        'Processing animations...',
      ],
    },
    FINALIZING: {
      name: 'Finalizing',
      icon: '‚ú®',
      messages: [
        'Writing file headers...',
        'Optimizing file size...',
        'Preparing for download...',
        'Final quality checks...',
        'Almost ready...',
      ],
    },
  };

  private constructor() {}

  /**
   * Initialize or resize reusable canvases to match the required dimensions
   */
  private initializeCanvases(width: number, height: number): void {
    // Initialize main canvas
    if (!this.mainCanvas) {
      this.mainCanvas = document.createElement('canvas');
      this.mainCtx = this.mainCanvas.getContext('2d', { willReadFrequently: true });
      if (!this.mainCtx) {
        throw createError('gif', 'Failed to create main canvas context');
      }
    }

    // Initialize recovery canvas
    if (!this.recoveryCanvas) {
      this.recoveryCanvas = document.createElement('canvas');
      this.recoveryCtx = this.recoveryCanvas.getContext('2d', { willReadFrequently: true });
      if (!this.recoveryCtx) {
        throw createError('gif', 'Failed to create recovery canvas context');
      }
    }

    // Resize canvases if dimensions changed
    if (this.mainCanvas.width !== width || this.mainCanvas.height !== height) {
      this.mainCanvas.width = width;
      this.mainCanvas.height = height;
    }

    if (this.recoveryCanvas.width !== width || this.recoveryCanvas.height !== height) {
      this.recoveryCanvas.width = width;
      this.recoveryCanvas.height = height;
    }
  }

  public static getInstance(): ContentScriptGifProcessor {
    if (!ContentScriptGifProcessor.instance) {
      ContentScriptGifProcessor.instance = new ContentScriptGifProcessor();
    }
    return ContentScriptGifProcessor.instance;
  }

  private updateStage(stageName: keyof typeof this.stages) {
    this.currentStage = stageName;
    this.messageIndex = 0;
    this.startMessageCycling();

    const stageInfo: StageProgressInfo = {
      stage: stageName,
      stageNumber: this.getStageNumber(stageName),
      totalStages: 4,
      stageName: this.stages[stageName].name,
      message: this.stages[stageName].messages[0],
      progress: this.getStageProgress(stageName),
    };

    this.progressCallback?.(stageInfo);
  }

  private getStageNumber(stageName: keyof typeof this.stages): number {
    const stageOrder = ['CAPTURING', 'ANALYZING', 'ENCODING', 'FINALIZING'];
    return stageOrder.indexOf(stageName) + 1;
  }

  private getStageProgress(stageName: keyof typeof this.stages): number {
    const stageNumber = this.getStageNumber(stageName);
    return ((stageNumber - 1) / 4) * 100;
  }

  private startMessageCycling() {
    // Clear existing timer
    if (this.messageTimer) clearInterval(this.messageTimer);

    if (!this.currentStage) return;

    // Cycle through messages every 3000ms
    this.messageTimer = setInterval(() => {
      if (!this.currentStage) return;

      const stage = this.stages[this.currentStage as keyof typeof this.stages];
      this.messageIndex = (this.messageIndex + 1) % stage.messages.length;

      const stageInfo: StageProgressInfo = {
        stage: this.currentStage,
        stageNumber: this.getStageNumber(this.currentStage as keyof typeof this.stages),
        totalStages: 4,
        stageName: stage.name,
        message: stage.messages[this.messageIndex],
        progress: this.getStageProgress(this.currentStage as keyof typeof this.stages),
      };

      this.progressCallback?.(stageInfo);
    }, 3000);
  }

  private stopMessageCycling() {
    if (this.messageTimer) {
      clearInterval(this.messageTimer);
      this.messageTimer = null;
    }
  }

  /**
   * Abort the current processing operation
   */
  public abortProcessing(): void {
    if (!this.isProcessing) {
      return;
    }

    logger.info('[ContentScriptGifProcessor] Aborting GIF processing');
    this.isAborting = true;
    this.abortRequestTime = Date.now();
    this.stopMessageCycling();
  }

  /**
   * Clear any stale abort state before starting new GIF creation
   * This prevents abort flags from previous sessions (SPA navigation, React remounts)
   * from incorrectly canceling new GIF creation attempts
   */
  public clearAbortState(): void {
    if (this.isAborting) {
      logger.warn('[ContentScriptGifProcessor] Clearing abort state before new GIF creation');
      this.isAborting = false;
      this.abortRequestTime = null;
    }
  }

  /**
   * Process video element to GIF entirely in content script
   */
  public async processVideoToGif(
    videoElement: HTMLVideoElement,
    options: GifProcessingOptions,
    onProgress?: (stageInfo: StageProgressInfo) => void
  ): Promise<GifProcessingResult> {
    if (this.isProcessing) {
      throw createError('gif', 'Already processing a GIF');
    }

    // Check if processing was aborted (should not happen if clearAbortState() was called)
    if (this.isAborting) {
      throw createError('gif', 'GIF creation was cancelled');
    }

    this.isProcessing = true;
    this.progressCallback = onProgress;
    const startTime = performance.now();

    try {
      logger.info('[ContentScriptGifProcessor] Starting GIF processing', { options });

      // Stage 1: Capturing Frames
      this.updateStage('CAPTURING');
      const frames = await this.captureFrames(videoElement, options);
      logger.info('[ContentScriptGifProcessor] Frames captured', { count: frames.length });

      // Stage 2: Analyzing Colors
      this.updateStage('ANALYZING');
      // Simulate color analysis time
      await new Promise((resolve) => setTimeout(resolve, 1000));

      // Stage 3: Encoding GIF
      this.updateStage('ENCODING');
      const gifBlob = await this.encodeGif(frames, options);
      logger.info('[ContentScriptGifProcessor] GIF encoded', { size: gifBlob.size });

      // Stage 4: Finalizing
      this.updateStage('FINALIZING');
      await new Promise((resolve) => setTimeout(resolve, 500));

      // Generate metadata
      const metadata = {
        fileSize: gifBlob.size,
        duration: options.endTime - options.startTime,
        frameCount: frames.length,
        width: frames[0]?.width || 320,
        height: frames[0]?.height || 240,
        fps: options.frameRate || 5, // Phase 2: Added for backend upload
        id: `gif_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      };

      // Complete
      this.stopMessageCycling();
      const finalStageInfo: StageProgressInfo = {
        stage: 'COMPLETED',
        stageNumber: 4,
        totalStages: 4,
        stageName: 'Complete',
        message: '‚úÖ GIF created successfully!',
        progress: 100,
      };
      onProgress?.(finalStageInfo);

      const processingTime = performance.now() - startTime;
      logger.info('[ContentScriptGifProcessor] Processing complete', {
        processingTime,
        metadata,
      });

      return { blob: gifBlob, metadata };
    } catch (error) {
      // Re-throw abort errors with a user-friendly message
      if (this.isAborting) {
        throw createError('gif', 'GIF creation was cancelled');
      }
      throw error;
    } finally {
      this.isProcessing = false;
      this.isAborting = false;
      this.stopMessageCycling();
      this.progressCallback = undefined;
    }
  }

  /**
   * Capture frames from video element
   */
  private async captureFrames(
    videoElement: HTMLVideoElement,
    options: GifProcessingOptions
  ): Promise<HTMLCanvasElement[]> {
    const { startTime, endTime, frameRate = 5, width = 480, height = 270 } = options;
    console.log(
      '[gif-processor] captureFrames - frameRate from options:',
      options.frameRate,
      'using:',
      frameRate
    );
    const duration = endTime - startTime;
    // Calculate proper frame count based on duration and frame rate
    const frameCount = Math.max(3, Math.ceil(duration * frameRate));
    const frameInterval = duration / frameCount;
    console.log('[gif-processor] captureFrames config', {
      duration,
      frameRate,
      frameCount,
      frameInterval,
      requested: { width, height },
    });

    logger.info('[ContentScriptGifProcessor] Capturing frames', {
      frameCount,
      frameInterval,
      dimensions: { width, height },
    });

    // Calculate actual dimensions maintaining aspect ratio
    // Use the requested dimensions exactly to match preset expectations (tests rely on fixed sizes)
    let actualWidth: number = width;
    let actualHeight: number = height;

    // Ensure even dimensions for video encoding
    actualWidth = Math.floor(actualWidth / 2) * 2;
    actualHeight = Math.floor(actualHeight / 2) * 2;

    logger.info('[ContentScriptGifProcessor] Calculated dimensions', {
      video: { width: videoElement.videoWidth, height: videoElement.videoHeight },
      requested: { width, height },
      actual: { width: actualWidth, height: actualHeight },
    });

    // Initialize reusable canvases with calculated dimensions
    this.initializeCanvases(actualWidth, actualHeight);

    const frames: HTMLCanvasElement[] = [];
    let consecutiveDuplicates = 0;
    // Adaptive threshold: ~2 seconds of duplicates based on frame rate
    // Minimum 10 frames, maximum 40 frames (increased for better buffering tolerance)
    const MAX_CONSECUTIVE_DUPLICATES = Math.max(10, Math.min(40, Math.ceil(frameRate * 2)));
    let totalDuplicates = 0;

    // Buffering tracking (Phase 1.1 + Always-visible UI)
    let frameCaptureStartTime = 0;
    let totalFrameCaptureTime = 0;

    // Store original state
    const originalTime = videoElement.currentTime;
    const wasPlaying = !videoElement.paused;

    // Pause for stable capture
    videoElement.pause();

    for (let i = 0; i < frameCount; i++) {
      // Check if processing was aborted
      if (this.isAborting) {
        // Restore video state before throwing
        videoElement.currentTime = originalTime;
        if (wasPlaying) {
          videoElement.play().catch(() => {});
        }
        throw createError('gif', 'GIF creation was cancelled');
      }

      const captureTime = startTime + i * frameInterval;

      // Start timing this frame capture (always-visible UI)
      frameCaptureStartTime = performance.now();

      logger.debug(
        `[ContentScriptGifProcessor] Seeking to ${captureTime.toFixed(2)}s for frame ${i + 1}`
      );

      // Seek to capture time
      const seekStartTime = performance.now();
      const previousTime = videoElement.currentTime;
      videoElement.currentTime = captureTime;

      // Wait for seek to complete using a combination of methods
      // First, wait a bit for the seek to initiate
      await new Promise((resolve) => setTimeout(resolve, 50));

      // Then poll to check if we're close to the target time AND video is ready
      let attempts = 0;
      const maxAttempts = 80; // 80 * 25ms = 2000ms max wait (increased for slow connections)
      let lastCheckedTime = videoElement.currentTime;
      let lastReadyState = videoElement.readyState;
      const pollStartTime = performance.now();

      // Keep polling until either:
      // 1. We're close to the target time AND video has buffered data, OR
      // 2. The video has stopped moving (stuck), OR
      // 3. We've hit the max attempts
      // 4. Processing was aborted
      while (attempts < maxAttempts && !this.isAborting) {
        const currentVideoTime = videoElement.currentTime;
        const distanceToTarget = Math.abs(currentVideoTime - captureTime);
        const currentReadyState = videoElement.readyState;

        // Check if position is close AND we have data
        // readyState >= 2 (HAVE_CURRENT_DATA) means we can render this frame
        if (distanceToTarget < 0.05 && currentReadyState >= 2) {
          // Additional check: verify the time is actually buffered
          const buffered = videoElement.buffered;
          let isBuffered = false;

          for (let bi = 0; bi < buffered.length; bi++) {
            if (buffered.start(bi) <= currentVideoTime && buffered.end(bi) >= currentVideoTime) {
              isBuffered = true;
              break;
            }
          }

          if (isBuffered) {
            logger.debug(
              `[ContentScriptGifProcessor] Seek complete and buffered at ${currentVideoTime.toFixed(3)}s (readyState=${currentReadyState}) after ${attempts} attempts`
            );
            break;
          }
        }

        // If the video hasn't moved and readyState hasn't changed, it might be stuck
        if (
          attempts > 10 &&
          Math.abs(currentVideoTime - lastCheckedTime) < 0.001 &&
          currentReadyState === lastReadyState
        ) {
          logger.debug(
            `[ContentScriptGifProcessor] Video appears stuck at ${currentVideoTime.toFixed(3)}s (readyState=${currentReadyState}) after ${attempts} attempts`
          );
          // Only break if we have at least some data
          if (currentReadyState >= 2) {
            break;
          }
        }

        lastCheckedTime = currentVideoTime;
        lastReadyState = currentReadyState;

        // Send buffering status update on EVERY poll attempt (Always-visible UI)
        if (attempts % 5 === 0 && attempts > 0) {
          // Send updates every 5 attempts (125ms intervals) instead of 10
          const pollDuration = performance.now() - pollStartTime;
          // Calculate buffered percentage for the target time
          const videoBufferedRanges = videoElement.buffered;
          let bufferedPercentage = 0;
          for (let bi = 0; bi < videoBufferedRanges.length; bi++) {
            if (
              videoBufferedRanges.start(bi) <= captureTime &&
              videoBufferedRanges.end(bi) >= captureTime
            ) {
              const nextFrameTime = startTime + (i + 1) * frameInterval;
              if (videoBufferedRanges.end(bi) >= nextFrameTime) {
                bufferedPercentage = 100;
              } else {
                const remaining = videoBufferedRanges.end(bi) - captureTime;
                bufferedPercentage = Math.floor((remaining / frameInterval) * 100);
              }
              break;
            }
          }

          // Estimate remaining time based on average frame time (including this wait)
          const estimatedFrameTime =
            totalFrameCaptureTime > 0 ? totalFrameCaptureTime / frames.length : pollDuration;
          const remainingFrames = frameCount - frames.length;
          const estimatedRemainingSeconds = (remainingFrames * estimatedFrameTime) / 1000;

          this.progressCallback?.({
            stage: 'CAPTURING',
            stageNumber: 1,
            totalStages: 4,
            stageName: 'Capturing Frames',
            message: `Waiting for frame ${i + 1}/${frameCount} to buffer...`,
            progress: this.getStageProgress('CAPTURING'),
            bufferingStatus: {
              isBuffering: true, // Actively waiting for buffer
              currentFrame: frames.length,
              totalFrames: frameCount,
              bufferedPercentage,
              estimatedTimeRemaining: Math.ceil(estimatedRemainingSeconds),
            },
          });
        }

        await new Promise((resolve) => setTimeout(resolve, 25));
        attempts++;
      }

      // Log if we timed out waiting for buffer
      if (attempts >= maxAttempts) {
        logger.warn(
          `[ContentScriptGifProcessor] Seek timeout for frame ${i + 1}: readyState=${videoElement.readyState}, time=${videoElement.currentTime.toFixed(3)}s`
        );
      }

      // Additional wait to ensure frame is decoded and rendered
      // This needs to be longer for seeks to non-keyframe positions or slow buffering
      const seekDistance = Math.abs(captureTime - previousTime);
      let additionalDelay = seekDistance > 2 ? 200 : 150; // Longer delay for longer seeks (increased)

      // Extra delay if readyState indicates potential buffering issues
      if (videoElement.readyState < 3) {
        additionalDelay += 200; // Add extra time when buffering (increased from 100ms)
      }

      // Additional delay for first few frames to give video decoder time to initialize
      if (i < 3) {
        additionalDelay += 100;
      }

      await new Promise((resolve) => setTimeout(resolve, additionalDelay));

      const seekDuration = performance.now() - seekStartTime;
      const actualTime = videoElement.currentTime;

      if (Math.abs(actualTime - captureTime) > 0.1) {
        logger.warn(
          `[ContentScriptGifProcessor] Seek inaccuracy for frame ${i + 1}: target=${captureTime.toFixed(2)}s, actual=${actualTime.toFixed(2)}s`
        );
      }

      logger.debug(
        `[ContentScriptGifProcessor] Seek completed for frame ${i + 1} in ${seekDuration.toFixed(0)}ms (target=${captureTime.toFixed(2)}s, actual=${actualTime.toFixed(2)}s)`
      );

      // Clear and reuse main canvas for this frame
      this.mainCtx!.clearRect(0, 0, actualWidth, actualHeight);

      // Draw video frame to reusable canvas
      this.mainCtx!.drawImage(videoElement, 0, 0, actualWidth, actualHeight);

      // Check for duplicate frames
      let isDuplicate = false;
      if (frames.length > 0) {
        const lastFrame = frames[frames.length - 1];
        if (areCanvasFramesSimilar(this.mainCanvas!, lastFrame)) {
          isDuplicate = true;
          consecutiveDuplicates++;
          totalDuplicates++;

          logger.warn(
            `[ContentScriptGifProcessor] ‚ö†Ô∏è DUPLICATE FRAME at ${i + 1}/${frameCount}: video stuck at ${videoElement.currentTime.toFixed(3)}s (wanted ${captureTime.toFixed(3)}s, prev was ${previousTime.toFixed(3)}s) [consecutive: ${consecutiveDuplicates}]`
          );

          // Abort if too many consecutive duplicates
          if (consecutiveDuplicates >= MAX_CONSECUTIVE_DUPLICATES) {
            // Restore video state before throwing
            videoElement.currentTime = originalTime;
            if (wasPlaying) {
              videoElement.play().catch(() => {});
            }

            throw createError(
              'video',
              `Video buffering too slow. Unable to capture frames after ${i + 1} attempts. Try:\n‚Ä¢ Waiting for video to fully buffer\n‚Ä¢ Using a shorter duration\n‚Ä¢ Reducing frame rate\n‚Ä¢ Checking your network connection`
            );
          }

          // Multi-strategy retry system (Phase 1.2)
          // Try recovery attempt on any duplicate (not just when time is wrong)
          // This helps when video is at correct time but frame hasn't decoded yet
          if (consecutiveDuplicates >= 2) {
            // Only start recovery after 2 duplicates to avoid unnecessary retries
            logger.info(
              `[ContentScriptGifProcessor] Attempting recovery for frame ${i + 1} (duplicate ${consecutiveDuplicates})`
            );

            // Define retry strategies
            const retryStrategies = [
              {
                name: 'time-nudge-small',
                delay: 300,
                apply: () => {
                  const timeOffset =
                    Math.abs(videoElement.currentTime - captureTime) > 0.01 ? 0.001 : 0.01;
                  videoElement.currentTime = captureTime + timeOffset;
                },
              },
              {
                name: 'buffer-wait',
                delay: 500,
                apply: () => {
                  // Re-seek to same position to trigger buffering
                  videoElement.currentTime = captureTime;
                },
              },
              {
                name: 'time-nudge-large',
                delay: 400,
                apply: () => {
                  // Larger nudge for stubborn cases
                  videoElement.currentTime = captureTime + 0.05;
                },
              },
              {
                name: 'backwards-seek',
                delay: 500,
                apply: () => {
                  // Seek backwards then forward to clear decoder state
                  videoElement.currentTime = Math.max(0, captureTime - 0.5);
                  setTimeout(() => {
                    videoElement.currentTime = captureTime;
                  }, 100);
                },
              },
            ];

            // Try strategies based on how many duplicates we've seen
            const strategyIndex = Math.min(consecutiveDuplicates - 2, retryStrategies.length - 1);
            const strategy = retryStrategies[strategyIndex];

            logger.info(
              `[ContentScriptGifProcessor] Trying recovery strategy: ${strategy.name} (attempt ${consecutiveDuplicates})`
            );

            // Apply strategy
            strategy.apply();
            await new Promise((resolve) => setTimeout(resolve, strategy.delay));

            // Clear and reuse recovery canvas for the recovery attempt
            this.recoveryCtx!.clearRect(0, 0, actualWidth, actualHeight);
            this.recoveryCtx!.drawImage(videoElement, 0, 0, actualWidth, actualHeight);

            // Check if recovery worked
            if (!areCanvasFramesSimilar(this.recoveryCanvas!, lastFrame)) {
              logger.info(
                `[ContentScriptGifProcessor] Recovery successful with ${strategy.name}! Now at ${videoElement.currentTime.toFixed(3)}s`
              );
              // Copy recovery canvas content to main canvas
              this.mainCtx!.clearRect(0, 0, actualWidth, actualHeight);
              this.mainCtx!.drawImage(this.recoveryCanvas!, 0, 0);
              isDuplicate = false;
              consecutiveDuplicates = 0; // Reset counter on successful recovery

              // Record successful recovery in telemetry (Phase 1.3)
              metricsCollector.recordUserAction('recovery-success', {
                frameNumber: i + 1,
                strategy: strategy.name,
                consecutiveDuplicates: consecutiveDuplicates,
              });
            } else {
              logger.warn(
                `[ContentScriptGifProcessor] Recovery strategy ${strategy.name} failed (attempt ${consecutiveDuplicates}), still stuck at ${videoElement.currentTime.toFixed(3)}s`
              );

              // Record failed recovery in telemetry (Phase 1.3)
              metricsCollector.recordUserAction('recovery-failed', {
                frameNumber: i + 1,
                strategy: strategy.name,
                consecutiveDuplicates: consecutiveDuplicates,
              });
            }
          }
        } else {
          // Frame is different, reset consecutive duplicate counter
          consecutiveDuplicates = 0;
        }
      }

      // Create a clone of the main canvas for the frames array
      // since we reuse the same canvas for all frames
      const frameCanvas = document.createElement('canvas');
      frameCanvas.width = actualWidth;
      frameCanvas.height = actualHeight;
      const frameCtx = frameCanvas.getContext('2d', { willReadFrequently: true });
      if (!frameCtx) {
        throw createError('gif', 'Failed to create frame canvas context');
      }
      frameCtx.drawImage(this.mainCanvas!, 0, 0);

      frames.push(frameCanvas);

      // Calculate frame capture metrics and send buffering status (Always-visible UI)
      const frameCaptureEndTime = performance.now();
      const thisFrameTime = frameCaptureEndTime - frameCaptureStartTime;
      totalFrameCaptureTime += thisFrameTime;
      const averageFrameTime = totalFrameCaptureTime / frames.length;

      // Calculate ETA based on average frame time
      const remainingFrames = frameCount - frames.length;
      const estimatedRemainingSeconds = (remainingFrames * averageFrameTime) / 1000;

      // Calculate buffered percentage
      const videoBuffered = videoElement.buffered;
      let bufferedPercentage = 0;
      for (let bi = 0; bi < videoBuffered.length; bi++) {
        if (videoBuffered.start(bi) <= captureTime && videoBuffered.end(bi) >= captureTime) {
          const nextFrameTime = startTime + (i + 1) * frameInterval;
          if (videoBuffered.end(bi) >= nextFrameTime) {
            bufferedPercentage = 100;
          } else {
            const remaining = videoBuffered.end(bi) - captureTime;
            bufferedPercentage = Math.floor((remaining / frameInterval) * 100);
          }
          break;
        }
      }

      // Send buffering status after successful frame capture (not actively buffering)
      this.progressCallback?.({
        stage: 'CAPTURING',
        stageNumber: 1,
        totalStages: 4,
        stageName: 'Capturing Frames',
        message: `Captured frame ${frames.length}/${frameCount}`,
        progress: this.getStageProgress('CAPTURING'),
        bufferingStatus: {
          isBuffering: false, // Normal capture, not waiting
          currentFrame: frames.length,
          totalFrames: frameCount,
          bufferedPercentage,
          estimatedTimeRemaining: Math.ceil(estimatedRemainingSeconds),
        },
      });

      // Export frame data for verification (in dev mode)
      if (typeof window !== 'undefined') {
        const win = window as Window & {
          __DEBUG_CAPTURED_FRAMES?: Array<{
            frameNumber: number;
            videoTime: number;
            targetTime: number;
            width: number;
            height: number;
            dataUrl: string;
            isDuplicate: boolean;
          }>;
        };
        if (!win.__DEBUG_CAPTURED_FRAMES) {
          win.__DEBUG_CAPTURED_FRAMES = [];
        }
        // Convert canvas to data URL for debugging
        const frameDataUrl = frameCanvas.toDataURL('image/png');
        win.__DEBUG_CAPTURED_FRAMES.push({
          frameNumber: i + 1,
          videoTime: videoElement.currentTime,
          targetTime: captureTime,
          width: actualWidth,
          height: actualHeight,
          dataUrl: frameDataUrl,
          isDuplicate: isDuplicate,
        });
      }

      logger.debug(
        `[ContentScriptGifProcessor] Captured frame ${i + 1}/${frameCount} at ${videoElement.currentTime.toFixed(2)}s (target: ${captureTime.toFixed(2)}s)`
      );
    }

    // Restore video state
    videoElement.currentTime = originalTime;
    if (wasPlaying) {
      videoElement.play().catch(() => {});
    }

    // Log final statistics
    const duplicatePercentage = (totalDuplicates / frameCount) * 100;
    logger.info('[ContentScriptGifProcessor] Frame capture completed', {
      totalFrames: frames.length,
      totalDuplicates,
      duplicatePercentage: duplicatePercentage.toFixed(1) + '%',
    });

    // Warn if significant duplicates detected (but still proceed)
    if (duplicatePercentage > 20) {
      logger.warn(
        `[ContentScriptGifProcessor] High duplicate rate (${duplicatePercentage.toFixed(1)}%). GIF quality may be affected by slow buffering.`
      );
    }

    return frames;
  }

  /**
   * Encode frames to GIF using encoder abstraction
   */
  private async encodeGif(
    frames: HTMLCanvasElement[],
    options: GifProcessingOptions
  ): Promise<Blob> {
    // Check if processing was aborted
    if (this.isAborting) {
      throw createError('gif', 'GIF creation was cancelled');
    }

    const { frameRate = 10, quality = 'medium' } = options;
    console.log('[gif-processor] encodeGif input', {
      frameRate,
      frameCount: frames.length,
      width: frames[0]?.width,
      height: frames[0]?.height,
    });
    console.log(
      '[gif-processor] encodeGif - frameRate from options:',
      options.frameRate,
      'using:',
      frameRate
    );

    try {
      // Convert canvas frames to encoder format
      const frameData: EncoderFrameData[] = frames.map((canvas, index) => {
        const ctx = canvas.getContext('2d', { willReadFrequently: true });
        if (!ctx) {
          throw new Error(`Failed to get context for frame ${index + 1}`);
        }

        // Apply text overlays if specified
        if (options.textOverlays && options.textOverlays.length > 0) {
          options.textOverlays.forEach((overlay) => {
            ctx.save();

            // Use font size directly - it's already resolution-appropriate from TextOverlayScreenV2
            ctx.font = `${overlay.fontSize}px ${overlay.fontFamily}`;
            ctx.fillStyle = overlay.color;
            ctx.textAlign = 'center';
            ctx.textBaseline = 'middle';

            // Calculate actual position (overlay.position is in percentage)
            const x = (overlay.position.x / 100) * canvas.width;
            const y = (overlay.position.y / 100) * canvas.height;

            // Use stroke width directly
            const strokeWidth = overlay.strokeWidth || 2;

            // Add text stroke for better visibility
            if (overlay.strokeColor) {
              ctx.strokeStyle = overlay.strokeColor;
              ctx.lineWidth = strokeWidth;
              ctx.strokeText(overlay.text, x, y);
            } else {
              // Default black stroke for better visibility
              ctx.strokeStyle = 'rgba(0, 0, 0, 0.8)';
              ctx.lineWidth = strokeWidth;
              ctx.strokeText(overlay.text, x, y);
            }

            // Draw the text
            ctx.fillText(overlay.text, x, y);

            ctx.restore();
          });
        }

        // Convert to EncoderFrameData format
        // Use GIF-native centisecond delay; keep timestamps in ms for ordering
        const delayCs = Math.max(2, Math.round(100 / frameRate)); // minimum 2cs to avoid collapse
        const delayMs = Math.round(1000 / frameRate);

        // Apply a tiny per-frame jitter to prevent encoder deduplication of identical frames
        if (index % 2 === 0) {
          ctx.save();
          ctx.globalAlpha = 0.002;
          ctx.fillStyle = 'rgba(0,0,0,0.5)';
          ctx.fillRect(0, 0, 1, 1);
          ctx.restore();
        }

        return {
          imageData: ctx.getImageData(0, 0, canvas.width, canvas.height),
          // Use millisecond timestamp and centisecond delay for GIF timing
          timestamp: index * delayMs,
          delay: delayCs,
        };
      });

      // Create encoding options
      const encodingOptions: EncodingOptions = {
        width: frames[0].width,
        height: frames[0].height,
        quality: quality,
        frameRate: frameRate,
        loop: true,
      };

      // Encode frames using the main encoder system
      const result = await encodeFrames(frameData, encodingOptions, {
        encoder: 'auto', // Let the system choose the best encoder
        format: 'gif',
      });

      logger.info('[ContentScriptGifProcessor] GIF encoding finished', {
        size: result.blob.size,
        metadata: result.metadata,
      });

      return result.blob;
    } catch (error) {
      console.error('[ContentScriptGifProcessor] Failed to encode GIF:', error);
      logger.error('[ContentScriptGifProcessor] Failed to encode GIF', { error });
      const errorMessage = error instanceof Error ? error.message : String(error);
      throw createError('gif', `Failed to encode GIF: ${errorMessage}`);
    }
  }

  // GIF data is no longer persisted to IndexedDB
  // Users download GIFs directly to their Downloads folder

  /**
   * Trigger download of GIF
   */
  public async downloadGif(blob: Blob, filename?: string): Promise<void> {
    const url = URL.createObjectURL(blob);
    const name = filename || `youtube-gif-${Date.now()}.gif`;

    // Send download request to background script
    chrome.runtime.sendMessage(
      {
        type: 'DOWNLOAD_GIF',
        data: {
          url,
          filename: name,
        },
      },
      (response) => {
        // Clean up blob URL after download starts
        setTimeout(() => URL.revokeObjectURL(url), 1000);

        if (response?.success) {
          logger.info('[ContentScriptGifProcessor] Download initiated', { filename: name });
        } else {
          logger.error('[ContentScriptGifProcessor] Download failed', { error: response?.error });
        }
      }
    );
  }

  /**
   * Phase 2: Save GIF with optional cloud upload
   *
   * Progressive enhancement strategy:
   * 1. ALWAYS download to Downloads folder first (never fails)
   * 2. OPTIONALLY upload to cloud if user is authenticated
   * 3. Return status of both operations
   *
   * @param blob - GIF blob to save
   * @param metadata - GIF metadata from processing
   * @param uploadParams - Parameters for cloud upload (title, YouTube URL, etc.)
   * @returns Promise with download and upload status
   */
  public async saveGifWithCloudUpload(
    blob: Blob,
    metadata: {
      fps: number;
      duration: number;
      width: number;
      height: number;
      frameCount: number;
      fileSize: number;
      id: string;
    },
    uploadParams: {
      title: string;
      youtubeUrl: string;
      timestampStart: number;
      timestampEnd: number;
      youtubeVideoTitle?: string;
      youtubeChannelName?: string;
      description?: string;
    },
    forceUpload: boolean = false
  ): Promise<{
    downloadSuccess: boolean;
    uploadSuccess: boolean;
    uploadedGif?: UploadedGif;
    uploadError?: string;
  }> {
    // Step 1: ALWAYS download to Downloads folder first
    const filename = `${uploadParams.title}-${Date.now()}.gif`;
    await this.downloadGif(blob, filename);
    logger.info('[ContentScriptGifProcessor] ‚úÖ GIF saved to Downloads folder', { filename });

    // Step 2: Check if user is authenticated
    const isAuthenticated = await StorageAdapter.isAuthenticated();

    if (!isAuthenticated) {
      logger.info('[ContentScriptGifProcessor] User not authenticated, skipping cloud upload');
      return {
        downloadSuccess: true,
        uploadSuccess: false,
      };
    }

    // Step 3: Get user preferences
    const preferences = await StorageAdapter.getAuthPreferences();

    // Check upload preferences (skip if forceUpload is true - manual upload via button)
    if (!forceUpload && preferences.autoUpload === false) {
      logger.info('[ContentScriptGifProcessor] Auto-upload disabled in preferences');
      return {
        downloadSuccess: true,
        uploadSuccess: false,
      };
    }

    // Step 4: Attempt cloud upload
    try {
      logger.info('[ContentScriptGifProcessor] üì§ Uploading GIF to cloud...', {
        title: uploadParams.title,
        size: blob.size,
      });

      const uploadGifParams: UploadGifParams = {
        file: blob,
        title: uploadParams.title,
        youtubeUrl: uploadParams.youtubeUrl,
        timestampStart: uploadParams.timestampStart,
        timestampEnd: uploadParams.timestampEnd,
        youtubeVideoTitle: uploadParams.youtubeVideoTitle,
        youtubeChannelName: uploadParams.youtubeChannelName,
        description: uploadParams.description,
        privacy: preferences.defaultPrivacy || 'public_access',
      };

      const uploadedGif = await apiClient.uploadGif(uploadGifParams);

      logger.info('[ContentScriptGifProcessor] ‚úÖ GIF uploaded to cloud', {
        gifId: uploadedGif.id,
        fileUrl: uploadedGif.file_url,
      });

      return {
        downloadSuccess: true,
        uploadSuccess: true,
        uploadedGif,
      };
    } catch (error) {
      logger.error('[ContentScriptGifProcessor] ‚ö†Ô∏è Cloud upload failed', { error });

      return {
        downloadSuccess: true,
        uploadSuccess: false,
        uploadError: error instanceof Error ? error.message : 'Unknown upload error',
      };
    }
  }
}

// Export singleton instance
export const gifProcessor = ContentScriptGifProcessor.getInstance();
